{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "The goal of this notebook is to load the dataset, tokenize and encode the data, train the model, evaluate it, and export the model.\n",
    "Adapted from https://huggingface.co/docs/transformers/main/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "d8K24Yy9m3sv"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1660 Ti'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 28 20:51:58 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 531.18       CUDA Version: 12.1     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce GTX 1660 Ti      On | 00000000:01:00.0  On |                  N/A |\r\n",
      "| N/A   51C    P5                9W /  N/A|    415MiB /  6144MiB |      1%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A        31      G   /Xwayland                                 N/A      |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1r_n9OWV3l-Q"
   },
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/atzenhofer/.cache/huggingface/datasets/json/default-a1523408e295402e/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c5fa9d63c64d84b7821513f9b08ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Wir Graf Hainreich von Schavnberg veriehen Offenlich an disem brief vnd , di in sehent, Hornt oder lesent, Das fur vns vnd fur vnsern brueder chomen ist der Erwirdig abpt datz wilhering vnd Her wernhart chelner da selben vnd der Erwerig wolbeschaiden Peter vnd hat der selb Peter pope nach vnserm rat vnd nach seiner besten vreunt rat vnd willen vnd wort aller seiner Erben dem vor geschriben erwirdigen Herren abpt dvrch sein recht notdurft vnd durch sein leibnar sein Hueb ze Strashaim , di Sein rechtz Erbaigen gewesen ist vnd di in von seinen vodern also Herman vnd das Gotzhaus ze wilhering di vorgenanten Hueb mit allen den rechten vnd gelegen sind, versuecht vnd vnuersuecht, durch di lieb vnd durch ze wilhering den vorgeschriben peter poppen begnat haben mit vntz an seinen tod in dem chloster vnd auch Hausfrawen frawen Ofmein vnd Jansen seins Suns. wer auch, das iemand , So geit der oft genant Peter Poppe Gotzhaus ze wilhering Sechtzich Phunt wienner Phenning auf der oft des selben an aller der stat, ob der Ens, vnd wort geschehen vnd vertaidingt an disem brief verschriben stet vnd lob laisten, stat haben vnd ze volfuren geuarde vnd dar vber zu gib ich disen brief dem oft geschriben Abbt Herman vnd dem Gotzhaus ze gnadigen Herren Graf gundem Insigel vnd mit wernhart des Hager vnd der Alhartinger. Das']}\n"
     ]
    }
   ],
   "source": [
    "train_data_file = \"../data-push/0d-sampling/train-validate/charters-main-train-data.json\"\n",
    "val_data_file = \"../data-push/0d-sampling/train-validate/charters-main-val-data.json\"\n",
    "# train_data_file = \"../data-push/0d-sampling/train-validate/charters-main-SAMPLE-train-data.json\"\n",
    "# val_data_file = \"../data-push/0d-sampling/train-validate/charters-main-SAMPLE-val-data.json\"\n",
    "\n",
    "datasets = load_dataset(\"json\", data_files={\"train\": train_data_file, \"validation\": val_data_file})\n",
    "\n",
    "print(datasets[\"train\"][:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-EIELH43l_T"
   },
   "source": [
    "## Masked language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "QRTpmyCc3l_T"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)#, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/atzenhofer/.cache/huggingface/datasets/json/default-a1523408e295402e/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-d303bdc26f349b55_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/atzenhofer/.cache/huggingface/datasets/json/default-a1523408e295402e/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-c719ab6830cb5940_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "LVYPMwEs3l_X",
    "outputId": "e71ed7f1-b182-4643-a8fb-3d731c70e40b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/atzenhofer/.cache/huggingface/datasets/json/default-a1523408e295402e/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-5d5957b7622f6692_*_of_00004.arrow\n",
      "Loading cached processed dataset at /home/atzenhofer/.cache/huggingface/datasets/json/default-a1523408e295402e/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-c5821ccb797a2bab_*_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=8, \n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nd durch ze wilhering den vorgeschriben peter poppen begnat haben mit vntz an seinen tod in dem chloster vnd auch Hausfrawen frawen Ofmein vnd Jansen seins Suns. wer auch, das iemand, So geit der oft genant Peter Poppe Gotzhaus ze wilhering Sechtzich Phunt wienner Phenning auf der oft des selben an aller der stat, ob der Ens, vnd wort geschehen vnd vertaidingt an disem brief verschriben stet vnd lob laisten, stat haben vnd ze volfuren geuarde vnd dar vber zu gib ich disen brief dem oft geschriben Abbt Herman vnd dem Gotzhaus ze gnadigen Herren Graf gundem Insigel vnd mit wernhart des Hager vnd der Alhartinger. Das</s><s>Wier Niclas von Gots genaden abbt ze Garsten verjehen, umb die schaden di wir mit mue und mit zerung gen'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "PM10A9Za3l_Z",
    "outputId": "fff2d5bb-397d-4d5d-9aa9-933090cb6680"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "O6zVkRyZm3tZ"
   },
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = f\"../models/custom/{model_name}-mhg-charter-mlm-v1\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Y9TFqDG_3l_e",
    "outputId": "2e0c8bca-0e04-4b4f-ad06-8dd320af6c37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atzenhofer/code/ma-thesis-dh-code/.venv/ma-thesis-dh-code/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10471\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13090\n",
      "  Number of trainable parameters = 82170201\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13090' max='13090' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13090/13090 1:45:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.537000</td>\n",
       "      <td>2.112094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.053400</td>\n",
       "      <td>1.838937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.900300</td>\n",
       "      <td>1.706654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.766200</td>\n",
       "      <td>1.607970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.669200</td>\n",
       "      <td>1.532340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.619100</td>\n",
       "      <td>1.490333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.571300</td>\n",
       "      <td>1.476035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.543100</td>\n",
       "      <td>1.428958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.517100</td>\n",
       "      <td>1.423216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.508300</td>\n",
       "      <td>1.408235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-1000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-1000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2615\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-1500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-1500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-2000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-2000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-2500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-2500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-2500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2615\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-3000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-3000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-3500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-3500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2615\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-4000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-4000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-4500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-4500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-5000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-5000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-5000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2615\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-5500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-5500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-6000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-6000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-6500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-6500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-6500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2615\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-7000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-7000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-7500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-7500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-7500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2615\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-8000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-8000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-8500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-8500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-9000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-9000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-9000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2615\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-9500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-9500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-10000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-10000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-10000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2615\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-10500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-10500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-11000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-11000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-11500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-11500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-11500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2615\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-12000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-12000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-12000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-12500\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-12500/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-12500/pytorch_model.bin\n",
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-13000\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-13000/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/checkpoint-13000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2615\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13090, training_loss=1.7973431872082994, metrics={'train_runtime': 6318.5307, 'train_samples_per_second': 16.572, 'train_steps_per_second': 2.072, 'total_flos': 6943414684124160.0, 'train_loss': 1.7973431872082994, 'epoch': 10.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4hSaANqj3l_g",
    "outputId": "eeeb8727-2e27-4aeb-ac71-c98123214661"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2615\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='327' max='327' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [327/327 00:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 4.07\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../models/custom/distilroberta-base-mhg-charter-mlm-v1\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(f\"../models/custom/{model_name}-mhg-charter-mlm-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/tokenizer_config.json\n",
      "Special tokens file saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/special_tokens_map.json\n",
      "Configuration saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/config.json\n",
      "Model weights saved in ../models/custom/distilroberta-base-mhg-charter-mlm-v1/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "tokenizer.save_pretrained(f\"../models/custom/{model_name}-mhg-charter-mlm-v1\")\n",
    "model.save_pretrained(f\"../models/custom/{model_name}-mhg-charter-mlm-v1\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Fine-tune a language model",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
